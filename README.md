# ğŸ‘‹ğŸ‘‹ Hello there, I'm Jie Xu

<div data-st-tgt="ee"><div jscontroller="YsfJcd" jsdata="HfR8Sd;_;A93aiw" jsaction="rcuQ6b:npT2md"><div jsname="yowaac" class="Ww4FFb x5EBlc zpLC1e gAW3sd"><div class="Y0MLFe lRe0Z" tabindex="0" role="button" aria-label="å¼€å§‹/åœæ­¢æ’­æ”¾é€‰å–æ¡†åŠ¨ç”»" style="align-items: center; justify-content: start; animation-duration: 25.8s;"><span class="thL3qf">ğŸ‚ hoa hoa hoa season ğŸ‚</span></div></div></div></div>

### Nice to meet you! 

I am a Chinese student pursuing a Ph.D. in Artificial Intelligence at Ajou University in Korea. Since September 2021, I have been working under the supervision of Prof. Wonjun Hwang in the AJOUCVPR Lab. My research interests during my Ph.D. studies include neural network quantization and knowledge distillation, utilizing the Information Theoretic Learning approach for image analysis. Before my Ph.D. study, I obtained my B.E. degree in Telecommunications and an M.Sc. in Computer Engineering from Jeju National University. During my undergraduate studies, it was best, as I received three Korean National Scholarships.

### My recent research interests include uncertainty awareness of the deep compression model for diffusion models.
1. Model Compression/Acceleration:  Information theoretic learning, Neural Network Pruning, Low-rank Approximation, Knowledge Distillation, Binary Neural Networks, and Signal processing.
2. Image-related tasks: Image classification, diffusion model.
3. Presented in 2024.8.25 - [2024.8æœˆæŠ¥å‘Šä¼š.pptx](https://github.com/user-attachments/files/16902694/2024.8.pptx)

Also, I am fond of mountaineering ğŸ—» and photography ğŸ“¸. I have visited several mountains in my hometown, including Huang Shan - é»„å±±, Zi Peng Shan - ç´«è“¬å±±, and Xiao Bie Shan - å°åˆ«å±±, all located in Anhui Province. Besides, I have been to 'í•œë¼ì‚° - æ±‰æ‹¿å±±' three times on Jeju Island in South Korea.

![wo(1)](https://github.com/Luadoo/Luadoo/assets/58927660/6dca96d0-d4c3-438b-8cce-0f79247e2c27)

## Updates

* April 2025: Progressive Quantization: Enhancing Stability in Binary Neural Networks (submission to MTA journal)
* May 2024: Starting to learn the diffusion model & quantization model. (3 months)
* Sep 2024: low-bit quantization PTQ for ImageNet classification.

## 2) Study by Coursera Course
* Neural Networks and Deep Learning - Andrew Ng, Kian Katanforoosh, Younes BensoudaMourri
* Machine Learning - - Andrew Ng
* Improving Deep Neural Networks: Hyperparameter Tuning, Regularization, and Optimization - Andrew Ng
* Fundamentals of Reinforcement Learning - - Martha White, Adam White
* TinyML and Efficient Deep Learning - MIT 6s965-Fall 2022 open tutorial
* TinyML and Efficient Deep Learning - MIT 6.5940-Fall 2023 open tutorial
* For learning the Diffusion model: https://learn.deeplearning.ai/accomplishments/0f02e4ca-56e7-49b7-a352-56e2c73b9182?usp=sharing
* Attention on 2024-WAIC technique speech
* Learned Sensetime OpenPPL
* Quantization in depth: https://learn.deeplearning.ai/accomplishments/e57f56f4-46d8-49c1-9910-9e5f9f9f479b
  
## 3) Techniques
* C++, Python, TensorFlow(a little), PyTorch, Matrix.
* Web development, Android application, Web crawler, RL, Recommendation System, QNN(quantization neural network), Computer Vision, Diffusion model.

  
## 4) Languages
* English Medium Level
* Korean High Level
* Chinese Mother tongue

## 5) Building Fully Connected Layers
* School Email: soark@ajou.ac.kr
* WeChat: kyen77-88_
* LinkedIn: https://www.linkedin.com/in/jie-xu-6a62461a1/
* Office: Ajou University, Paldal Hall, 913-2 room.
* 
## 6) Methods:
1. QAT: LSQ(activation quantization), DSQ, QIL, LQW, LQ-Nets, PACT, DoReFa-Net, LSQ++, PACT, MQBench, Quantization Networks,

2. PTQ: RAPQ, ACIQ, LAPQ, INQ, AdaRound(weight quantization), BRECQ(both quantization with asymmetric), QDrop, Mr.BiO(both quantization with symmetric), PD-Quant, MRECG, EMA BRECQ++, NWQ, 

3. BNN - BNN Evolution-based algorithm
4. KD + BNN + Pruning
5. é‡åŒ–æ¨¡å‹éƒ¨ç½²/æ¨¡å‹è½¬æ¢æ¶æ„:
parser - optimizer - calibrator - quantizer - debugger 

## 7. Previous MPQ methods:
1. Search-based: high computation cost of NAS or RL
2. Metric-based: sub-optimal generated MPQ strategy(éœ€è¦äººä¸ºè°ƒæ§)
3. Optimization-based: inaccurate gradient approximation
<a target="_blank" rel="noopener noreferrer nofollow" href="https://komarev.com/ghpvc/?username=Luadoo&color=blue&style=for-the-badge">
    <img src="https://komarev.com/ghpvc/?username=Luadoo&color=green&style=plastic" alt="Profile Views" style="max-width: 100%;">
</a>

