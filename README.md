# 👋👋 Hello there, I'm Jie Xu

## 1) Latent Representation


### Nice to meet you! 

I am a Chinese student pursuing a Ph.D. in Artificial Intelligence at Ajou University in Korea. Since September 2021, I have been working under the supervision of Prof. Wonjun Hwang. My research interests during my Ph.D. studies include neural network quantization and knowledge distillation, utilizing the Information Theoretic Learning approach for image analysis. Before my Ph.D. study, I obtained my B.E. degree in Telecommunications and an M.Sc. in Computer Engineering from Jeju National University. During my undergraduate studies, it was best, as I received three Korean National Scholarships. And my Ph.D. research is supported by the Brain Korea Scholarship.

### My recent research interests include uncertainty awareness of the deep compression model for diffusion models.
1. Model Compression/Acceleration:  Information theoretic learning, Neural network Pruning, Low-rank Approximation, Knowledge Distillation, Binary Neural Networks, and Signal processing.
2. Image-related tasks: Image classification, diffusion model.
3. Presented in 2024.8.25 - [2024.8月报告会.pptx](https://github.com/user-attachments/files/16902694/2024.8.pptx)

Also, I am fond of mountaineering 🗻 and photography 📸. I have visited several mountains in my hometown, including 'Huang Shan - 黄山', 'Zi Peng Shan - 紫蓬山', and 'Xiao Bie Shan - 小别山', all located in Anhui Province. Besides, I have been to '한라산 - 汉拿山' three times on Jeju Island in South Korea.

![wo(1)](https://github.com/Luadoo/Luadoo/assets/58927660/6dca96d0-d4c3-438b-8cce-0f79247e2c27)

## Updates

* Jan 2024: One paper on the quantization model is submitted to the journal.
* May 2024: Starting to learn the diffusion model & quantization model.
* Sep 2024: low-bit quantization PTQ for ImageNet classification.

## 2) Study by Coursera Course
* Neural Networks and Deep Learning - - Andrew Ng, Kian Katanforoosh, Younes BensoudaMourri
* Machine Learning - - Andrew Ng
* Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization - - Andrew Ng
* Fundamentals of Reinforcement Learning - - Martha White, Adam White
* TinyML and Efficient Deep Learning - MIT 6s965-Fall 2022 open tutorial
* TinyML and Efficient Deep Learning - MIT 6.5940-Fall 2023 open tutorial
* For learning the Diffusion model: https://learn.deeplearning.ai/accomplishments/0f02e4ca-56e7-49b7-a352-56e2c73b9182?usp=sharing
* Attention on 2024-WAIC technique speech
* Learned Sensetime OpenPPL
  
## 3) Techniques
* C++, Python, TensorFlow(a little), PyTorch, Matrix.
* Web development, Android application, Web crawler, RL, Recommendation System, QNN(quantization neural network), Computer Vision, Diffusion model.

  
## 4) Languages
* English Medium Level
* Korean High Level
* Chinese Mother tongue

## 5) Building Fully Connected Layers
* School Email: soark@ajou.ac.kr
* WeChat: kyen77-88_
* LinkedIn: https://www.linkedin.com/in/jie-xu-6a62461a1/
* Office: Ajou University, Paldal Hall, 913-2 room.
* 
## 6) Methods:
1. QAT: LSQ(activation quantization), DSQ, QIL, LQW, LQ-Nets, PACT, DoReFa-Net, LSQ++, PACT, MQBench, Quantization Networks,

2. PTQ: RAPQ, ACIQ, LAPQ, INQ, AdaRound(weight quantization), BRECQ(both quantization with asymmetric), QDrop, Mr.BiO(both quantization with symmetric), PD-Quant, MRECG, EMA BRECQ++, NWQ, 

3. BNN - BNN Evolution-based algorithm
4. KD + BNN
5. Pruning + BNN
6. 量化模型部署/模型转换架构
parser - optimizer - calibrator - quantizer - debugger 

7. Previous MPQ methods:
1.) Search-based: high computation cost of NAS or RL
2.) Metric-based: sub-optimal generated MPQ strategy(需要人为调控)
3.) Optimization-based: inaccurate gradient approximation
<a target="_blank" rel="noopener noreferrer nofollow" href="https://komarev.com/ghpvc/?username=Luadoo&color=blue&style=for-the-badge">
    <img src="https://komarev.com/ghpvc/?username=Luadoo&color=green&style=plastic" alt="Profile Views" style="max-width: 100%;">
</a>

